{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_with_tensorflow.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP9b2Z1PYNQv8yNyMZDXQkN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajulearner/__tensorflow__/blob/master/ANN_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsXdsfQpqoNc",
        "colab_type": "text"
      },
      "source": [
        "What is **ANN**?<br>\n",
        "\n",
        "\n",
        "> Artificial Neural Networks (ANN) is a supervised learning system built of a large number of simple elements, called neurons or perceptrons. Each neuron can make simple decisions, and feeds those decisions to other neurons, organized in interconnected layers.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> <i>The basic functioning of Artificial Neural Net(ANN) is inspired by working of biological neuron. Human brain learns as a result of getting trained by sample data initially. For example, we learn to call a fruit-apple after initally getting “trained” to see the apple as object in real life or it’s image.</i>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> The most simple neural network is the <b> “perceptron”</b>, which, in its simplest form, consists of a single neuron. Much like biological neurons, which have dendrites and axons, the single artificial neuron is a simple tree structure which has input nodes and a single output node, which is connected to each input node.</b>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXJ8TlNStOdG",
        "colab_type": "text"
      },
      "source": [
        "#Shallow vs Deep Neural network\n",
        "\n",
        "\n",
        "\n",
        "> In <b>Shallow Neural network</b>, there will be only one <i> hidden</i> layer between input and output layers.\n",
        "\n",
        "\n",
        "> In <b> Deep Neural network</b> , there will more than one <i> hiddden </i> layers between input and output layers.\n",
        "<hr><hr><br><br>\n",
        "<img src=\"https://missinglink.ai/wp-content/uploads/2018/11/networkgraph-1.png\"></img>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzHSaE3WxW1T",
        "colab_type": "text"
      },
      "source": [
        "**What is Activation Function?** <br>\n",
        "If we do not apply a Activation function then the output signal would simply be a simple linear function.A linear function is just a polynomial of one degree. Now, a linear equation is easy to solve but they are limited in their complexity and have less power to learn complex functional mappings from data. A Neural Network without Activation function would simply be a Linear regression Model, which has limited power and does not performs good most of the times.\n",
        "<li>Sigmoid <br>\n",
        "<li>Tanh <br>\n",
        "<li>ReLu<br>\n",
        "<li>LeakyReLu</li>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvG_VRyMx5bP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}